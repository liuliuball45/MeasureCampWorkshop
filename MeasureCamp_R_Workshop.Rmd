---
title: 'MeasureCamp R Workshop'
subtitle: 'The Basics of R'
author: "Longhow Lam"
output:
   prettydoc::html_pretty:
     highlight: github
     theme: cayman
     toc: true
     toc_depth: 2
     number_sections: true
   pdf_document:
     toc: yes
     toc_depth: '2'
   html_notebook:
     theme: sandstone
     toc: true
     toc_depth: 2
     toc_float: true
     number_sections: true
---


![](measurecamp.PNG)


<br>

! WARNING !  **This document will contain more material than I can handle during the 3 hour workshop. But don't worry that is OK**

<br>

# The RStudio Environment

---


Start with powerpoint slides over R followed by an intro in RStudio:

* Console,
* Script windows,
* Environment tab (Object browser),
* Packages.

![](RStudio.png)

## The R Console

The R Console is a place where you can quickly run a short piece of code. Type in an R expression and Enter to run. Output of scripts also appears in the R Console.


## Scripts 

R Script files are ordinary text files (*.R) with R code. In RStudio you can open and edit multiple scripts. Scripts that belong together can be put in an R Project. Via the File menu> New File> R Script you can create a new R script file in RStudio. Or use the short cut: Ctrl + Shift + N.

In an R script you type code and if you move the cursor on a line you can run that line of code by pressing `Ctrl + Enter`. You can also select multiple lies and run these lines with `Crtl + Enter`. For more options see the Code menu and 'Run Region'.


## R Notebooks / R Markdown files

R notebooks and R Markdown files contain more than just R code, it is a 'complete' document with R code, output and a descriptive story line. In an R project you can also manage several of these notebooks (or markdown files) and scripts. Note books are created with R markdown, a sort of light weight markup language in which you can specify headers, figures and bold prints, for example. This R course is written in an R markdown file. A notebook / markdown file contains ** R code chunks** that you can run.

If you press the 'Preview' button above the R notebook you will see a separate window with the **result of the R notebook**. Therefore, RStudio creates a separate file that has the name `<file_name>.nb.html`. This is a html file that you can share with others.
 
Besides the nb.html, you can also "knit" an R notebook / markdown file into an html, pdf or Word document. The header of the markdown document tells how to knit a few things. See for example this document. Next to the 'Preview' button you will see an arrow from which you can choose.


## R Projecten

Organize your R work in projects. A project can consist of different scripts, notebooks, data and output, which you would like to have in one folder. In RStudio you can work very conveniently with different R projects. Through the RStudio interface you can create and manage projects: File> New Project...


## Git version control

Git is a version control system. In RStudio you can easily use git. You will have to install it first. On Windows you can install git via [the git site] (https://git-scm.com/download/win). We will not discuss Git further in this workshop.


## A few simple R expressions to get started

In the code chunk below you'll find some simple R expressions to get started.

```{r, eval=FALSE}
1 + 1
print("hello world")

## assignment kan je = of <- gebruiken,
## pijltje stamt nog uit een tijd waar het een toets op het toetsenbord was

## Als je onderstaande regel runt wordt het object test gemaakt, je ziet nog verder niks
test = 9

## Om te zien wat er in het object test zit moet je het printen
## Dit doe je door het volgende code te runnen, nu zie je iets verschijnen
print(test)

## Omdat je best vaak snel wilt zien wat er in een object zit volstaat alleen de naam ook
## dus run de volgende regel
test

## als een object al bestaat wordt die zonder waarschuwingen overschreven
test <- 3
test
```


# Data types 

---

All data in R is of a certain type, we will discuss the different data types in the sections below. with the `typeof` function you can always request the type of an object in R.

## Numerical data

### Double data type

The `double` datatype in R is often used to represent numerical values, (let's day 'everyday' numbers). For example, in a medical data set, height (1.85) or weight (78.8) of patients.

```{r, eval=FALSE}
x4 = 4
x5 = 5.6 / 8

x6 = pi/2

is.double(x4)
typeof(x4)
```


### Integer data type

The `integer` data type in R also represent numerical values. In contrast to doubles they represent only natural numbers. For example a count variable: the number of children (0, 1, 2, ... ).


```{r, eval=FALSE}
# let op, onderstaande zijn nog doubles in R.
x = 1
y = 2

is.integer(x)

x = as.integer(1)
z = x + 9.78

is.integer(z)

y = 34L
is.integer(y)

x7 = 4L
is.double(x7)

# in tegenstelling tot sommige andere talen kan je in R double en integers 
# in berekeningen zonder vertalingen gebruiken

x8 = x4 + x7
typeof(x8)
```

## Character data type

In R you can use the `character` data type to work with texts (text data), or often also called strings. Operations and manipulations of characters are explained later on in this workshop.


```{r, eval=FALSE}
x1 = "Longhow Lam"
x2 = "1628 AA Hoorn"

is.character(x1)

nchar(x2)

x3 = paste(x1, x2)
x3 = paste(x1, x2, sep="")
x3 = paste0(x1, x2)
```


## Factor data type

In R, `factors` are meant to represent categorical variables. For example, gender, or education. Do not confuse a factor with the character type, you can create factor variables from character variables. In some predictive modeling functions you explicitly need factor variables and not character.

Consumer data sets may include names or surnames of persons, these are often character data type. But for example the gender or education are often of the type of factor.


```{r, eval=FALSE}
x3 = c("M", "F", "M")

is.character(x3)
typeof(x3)

y3 = as.factor(x3)
x3
y3
```


## Logical data type

If you run a test in R, then the result is of the type `logical`. We already saw the functions `is.double` and` is.integer`, which returned an object of type logical.


```{r, eval=FALSE}
x7 = TRUE
x8 = FALSE

typeof(x7)

# test if an object is smaller than a value
x9 = x6 < 8

is.logical(x9)

x1 = as.integer(1)
x2 = 1

x1
x2
```

Note that in R, you can test if a double object is equal to an integer object, in some other languages this is not possible.

```{r, eval = FALSE}
is.integer(x2)
is.integer(x1)

x1 == x2
```

The next block of code shows logical operators.

```{r, eval=FALSE}
# ampersand: use it to test AND
TRUE & FALSE    # AND

x = 9
x < 10 & x > 5

# negate (NOT) 
!TRUE           # NOT
!FALSE

# OR
TRUE | FALSE    # OR
x < 7 | x > 8
```

In R you can use logical data in calculations.

```{r, eval = FALSE}
TRUE + TRUE
FALSE + FALSE + TRUE

x = rnorm(10000)
sum(x>2)
```


## Missing values

Missing values can be represented in R with `NA`. You can have missing doubles, integers, etc.

```{r, eval=FALSE}
x3 = NA

# gebruik is.na om te checken of iets NA is
is.na(x3)

# een rijtje getallen waarbij eentje missend is
x4 = c(1, 2, 3, 4, NA, 5, 7)

# hoeveel elementen zijn NA en niet NA
sum(is.na(x4))
sum(!is.na(x4))

x4 < 4

is.na(x4)
```



# Data structures

---

Data in R can appear in different forms, the so-called data structures. We will discuss a number of basic structures below.


## Vectors

Vectors are used to store a 'row' of elements. You can have a vector of doubles, characters etc ... All elements can only be of the same type!


```{r, eval=FALSE}
## een getal is ook al een vector, van lengte 1
x0 = 1

x1 = c( 1, 2, 3, 4, 5)
length(x1)
class(x1)

x2 = c(2L, 3)
typeof(x2)

x3 = c("p", 2)
```

There are several functions in R that you can use to generate vectors without typing all the elements one by one :-)

```{r, eval = FALSE}
x1 = 1:1000
x1 = 187:278

x2 = seq(1, 50, length=100)
x2a = seq(1,500, by = 20)

## combining two or more vectors
x3 = c( x0, rnorm(100))

class(x4)
```

Generating some random numbers is useful for quickly having some data to test, in R there are various functions.

```{r, eval=FALSE}
# normaal verdeelde getallen
rnorm(100)
rnorm(100, 9, 2)

#uniform verdeelde getallen
runif(100)
runif(100,8,10)

# trekken uit een vector
x4 = sample( letters, rep = TRUE, size = 100)
```

Calculations on vectors take place on element level by default.

```{r, eval=FALSE}
y = 3 * x3 + 8

## en wat is dit???
y = x4 + 8

x4 = rep(1:6, 7)
x4 = rep(x4,8)

x5 = rep(1:10, each = 3)
```

The `cut` function to make factor vectors from double vectors.

```{r}
x = rnorm(100)
y = cut(x, 4)
```


### Subscripting of vectors

How do you approach elements in a vector? That is possible with subscripts.

```{r, eval=FALSE}
## R begint te tellen bij 1
x3 = 100:200

## subscripts zijn : 1 getal, een vector van getallen, negatieve getallen
x3[1]
x3[  4:10  ]
x3[  -(1:10)]

## gebroken kan ook...
x3[8.9]

## je kan met subscripts ook elementen veranderen
x3[  8:17  ] = 0
```

You can also specify a vector of TRUE / FALSE as a subscript, then only the TRUE values are taken.

```{r, eval=FALSE}
x = rnorm(100)
x[x > 2]

```

A few simple functions that you can apply to vectors

```{r, eval=FALSE}
y = rnorm(1000)

mean(y)
var(y ) 
min(y)
sd(y)
max(y)
summary(y)

sum(y < 0)
```


##  Matrices

A matrix is a collection of vectors that are of the same length. You can have rectangular matrices (number of rows smaller or larger than number of columns) or you can have square matrices (number of rows = number of columns).


```{r, eval=FALSE}
## maak een matrix van een vector
m1 = rnorm(100)
m2 = matrix(m1, byrow = FALSE, ncol=10)
m2
dim(m2)
class(m2)

## maak een matrix van een aantal vectoren
x = 1:10
y = 10:1
z = 11:20

m3 = cbind(x,y,z)
m4 = rbind(x,y,z)
```

Just like vectors you can access elements in a matrix with subscripts, below are a few examples.

```{r, eval = FALSE} 
m2[1,5]

m2[  4:10,    3:5]

m2[5,]

m2[ ,5]
```

If you have matrices in R you can perform mathematical (linear algebra) calculation on them. A few examples: determinant, transpose and inverse.

```{r, eval =FALSE}
# determinant van een matrix
det(m2)

# matrix transponeren
t(m2)

# inverse van een matrix
solve(m2)

# er zijn twee soorten vermenigvuldigingen van matrices
m2 %*% solve(m2)
m2 * solve(m2)

round(m2 %*% solve(m2))
```

## Data frames

A data frame can be seen as a matrix, but unlike a matrix, columns of a data frame can be of a different data type. For data analysis with 'real' data, a data frame will be the most useful structure. For example, you have a factor column 'Gender', double columns with 'Age' and 'Income' and you can have a character column with 'surname'.

```{r, eval=FALSE}
x1 = 1:100
x2 = rnorm(100)
x3 = rnorm(100)
x4 = sample(c("M","F"), size = 100, replace = TRUE)

df1 = data.frame(
  kolomnaampj1 = x1,
  income = x2,
  age = x3,
  type = x4
)

# laat eerste 10 rijen zien
head(df1,10)
```

The following functions can be used to show some extra information from a data frame.

```{r, eval=FALSE}
# laat de namen van de kolommen zien
names(df1)

# names kan je ook gebruiken om bestaande kolomnamen te wijzigen
df2 = df1
names(df2) = c("A", "B", "C", "D")

# dimensie en classe
dim(df1)
class(df1)

# De levels van kolom 'type' uit mydf
levels(mydf$type)

### pas op met characters die worden standaard in data.frame naar factors omgezet
x4
class(x4)
class(df1$type)

mydf = data.frame(
  kolomnaampj1 = x1, 
  income = x2, 
  age = x3,
  type = x4,
  stringsAsFactors = FALSE
)
mydf

class(mydf$type)

## Dit is ook in de Environment viewer te zien
```


Just like with matrices, you can use subscripts in data frames to extract certain parts from a data frame.

```{r, eval=FALSE}
df1[1,3]
df1[11:20,]

df1[, 2:3]
df1$income

## kolom toevoegen
df1$NEW = df1$income / 100
df1
```


# Importing data

---

## The 'Import Dataset' gui

Just under the 'Environment' tab there is an *Import Dataset* menu that you can use to import data sets from the GUI.

## The Import functions

If want to analyze data in R, you obviously need data. Until now we have created our data manually with code. In real life you have already data in files or databases.

There are a number of packages that are useful for reading files.

* `readr` package, for text files
* `haven` package for files from SAS, SPSS, Stata
* `readxl` for Excel files

Base R also has standard functions for importing text files, but I often use the functions from the `readr` package. It is much faster for larger files, and you will also see a progress bar. In RStudio, you can also call the import functions via the ** Import Dataset ** GUI which guides you through the process of importing data.

```{r, eval=FALSE}
### data met restaurants in Nederland
library(readr)
Restaurants = read_csv("Restaurants.csv")

### Excel files inlezen
library(readxl)
test = read_excel(
  "test.xlsx",
  range = "D8:F14"
)
```

## RDS files

You can save R objects (not only data frames) with the `saveRDS` function, and these can be imported back into R again with the` readRDS` function. The files that `saveRDS` creates are binary files, they are smaller than text files and are faster to read in R again.

```{r, eval = FALSE}
x = rnorm(100)
saveRDS(x, "x.RDs")
```

## Database connection

In R you can connect to external databases, like MySQL or SQL Server, but also to data in HIVE or Spark. You can use odbc, and on Linux there is config file to specify the connection to the specific database. An example is given below where an odbc connection is used to connect to a MySQl database server via a .my.conf file in Linux

![](odbcini.PNG)

Now that there connection named `my-connector` we can use that in R to connect.

```{r, eval = FALSE}
library(odbc)
library(DBI)
library(dplyr)
con = dbConnect(odbc::odbc(), "my-connector")
```

Or you can use a connection string like the examples below, which also works on Windows machines. The first one is a connection to MySQL.

```{r eval = FALSE} 
con <- dbConnect(
  odbc::odbc(),
  .connection_string = "Driver={MySQL ODBC 5.3 ANSI Driver};user=root; password=mysqlroot; database=r_test"
)
cars = tbl(con, "mtcars") %>%  collect()
```

The follwoing example connects to SQL Server on Windows

```{r eval = FALSE}
# explicit password in script
con = DBI::dbConnect(
  odbc::odbc(),
  Driver   = "SQL Server",
  Server   = "DESKTOP-5JI7FPP",
  Database = "rtest",
  UID      = "sa",
  PWD      = "sqlserverroot",
  Port     = 1433
)

# using ask for password
con = DBI::dbConnect(
  odbc::odbc(),
  Driver   = "SQL Server",
  Server   = "DESKTOP-5JI7FPP",
  Database = "rtest",
  UID      = rstudioapi::askForPassword("Database user"),
  PWD      = rstudioapi::askForPassword("Database password"),
  Port     = 1433
)

cars = tbl(con, "mtcars") %>%  collect()

dbDisconnect(con)
```


In the RStudio GUI you can see (only for certain connections) the data tables in the data base server.

![](connections.PNG)

For more details on connecting R to a database see [this website](https://db.rstudio.com/overview).

---

# Data preparation and manipulation

---

## The dplyr library

---

This library is very useful to prepare data in R. The syntax is elegant and dplyr code can also be used for data that is not in R. For example, data in Spark can be edited with dplyr code. There are many "key" functions, but the most important ones are `select`,` filter`, `mutate`,` arrange`, `summarize`,` slice` and `rename`. The nice thing about these functions is that they can be used with the `%>%` chain operator. 

### Seleceting columns with `select`

```{r, eval=FALSE}
## enkele kolommen selecteren
my.cars = select(mtcars, hp, mpg, drat)

## via de chain operator, dit is niet alleen handig maar zo kan je verschillende operaties achter elkaar plakken.
my.cars = mtcars %>% 
  select(
    hp, 
    mpg,
    drat
  )

## meerdere kolommen selecteren
test1 = iris %>% 
  select(
    starts_with("Petal")
  )

## bepaalde kolommen selecteren
test2 = mtcars %>% 
  select(
    contains("pg"),
    starts_with("c")
  )

my.cars = mtcars %>% .[2:6]
```

### Create columns with `mutate`

We already saw that you could add extra columns to a data frame with the `$` operator 

```{r, eval=FALSE}
my.cars$kolom2  = rnorm(32)
my.cars$kolom3  = my.cars$kolom2 + 9
```

With the function`mutate` you can do this as well.

```{r, eval=FALSE}
mycars = mtcars %>%
  select(
    disp, 
    mpg 
  ) %>%
  mutate(
    displ_l = disp / 61.0237,
    tmp = mpg *1000
  )
```

You can create new columns that depend on columns that you just create in mutate.

```{r, eval=FALSE}
mycars = mtcars %>%
  mutate(
    displ_l = disp / 61.0237,
    tmp = mpg *1000,
    tmp2 = tmp + 1
  )
```

### Create `distinct` rows

To de-duplicate data in a data set, use the function `distinct`.

```{r, eval=FALSE}
distinct( select(mtcars, carb, gear))

distinct(select(mtcars, 10,11))

### pipe / chain operatie
myset = mtcars %>% 
  select(10,11) %>%
  distinct
```

### Selecting rows from data with `filter`

With the functions `filter` and `slice` you can select records / rows from a data frame. 

```{r, eval=FALSE, include=FALSE}
filter(
  mtcars, 
  cyl == 8 & gear > 3
)

## meerdere filter expressie bekenen EN

filter(
  mtcars, 
  cyl == 8,
  gear > 3
)

## als je of wilt moet je | gebruiken

filter(
  mtcars, 
  cyl == 8 | gear > 3
)
```

With `slice` you can take rows based on row numbers from a data set. For example the first 8 records, or record 8 until the last one.

```{r, eval=FALSE}
slice(mtcars, 1:8)
slice(mtcars, 8:n())
```

### Aggregating data sets 

The functions `group_by` and `summarise` are often used together to aggregate data.

```{r, eval=FALSE}
## apart aanroep van group_by en summarise... zo kan je zien wat group_by oplevert
by_cyl = group_by(mtcars, cyl) 
class(by_cyl)

summarise(by_cyl, Naampje1 = mean(disp), Naampje2 = mean(hp))

## maar vaak doe je de twee in 1 run samen
out = mtcars %>%
  group_by(
    cyl
  ) %>% 
  summarise(
    mdisp = mean(disp),
    mhp = mean(hp)
  )

out = filter(
  mtcars, mpg > 11
  ) %>%
  group_by(
    cyl, 
    carb
  ) %>% 
  summarise(
    N = n(), 
    MeanDisp = mean(disp),
    SD_HP = sd(hp)
  )
```


The function `top_n`, selecting the top 4 rows form mtcars (based on the variable hp).

```{r eval = FALSE}
mtcars %>%  top_n(4, hp)
```


### Window functions

dplyr supports so-called SQL window functions. For example, determine per cyl value the ranking of hp.

```{r, eval = FALSE}
 TMP = mtcars %>%
  group_by(
    cyl
  ) %>%
  mutate(
    rank = rank(desc(hp), ties.method = "first")
  ) %>%
  select(cyl, hp, rank)
```

Now per cyl value, we can select the car with largest hp value.

```{r, eval = FALSE}
TMP = mtcars %>%
  group_by(
    cyl
  ) %>%
  mutate(
    rank = rank(desc(hp), ties.method = "first")
  ) %>%
  filter(rank ==1)
```

### Joining data sets

With dplyr you can easily join data frames. There are several joins that are supported. We give a number of examples here. First create two dummy data sets.


```{r, eval=FALSE}
df1 = data.frame(
  col1 = c(1,2,3,4,5), tt = rnorm(5)
)

df2 = data.frame(
  col1 = c(3,4,5,6,7), xx = rnorm(5), zz = runif(5)
)

```

Now perform some different joins on the two data sets.


```{r, eval = FALSE}
## selecteer rijen die zowel in df1 en df2 zitten 
df3 = inner_join(
  df1, 
  df2,
  by = c("col1" = "col1")
)

## alle rijen die in df1 zitten, geen match levert NA op
df4 = left_join(
  df1,
  df2,
  by = c("col1" = "col1")
)

## alle rijen die in df2 zitten
df5 = df1 %>% right_join(
  df2,
  by = c("col1" = "col1")
)

## alleen de rijen van df1 die niet in df 2 zitten
df6 = df1 %>% anti_join(
  df2,
  by = c("col1" = "col1")
)

## alle rijen van df1 en df2
full_join(df1, df2, by = c("col1" = "col1"))
```

<br>

## Stack or bind data sets

Sometimes you want to stack two tables on top of each other into a new table, you can do that with `bind_rows`. If you want to put two tables next to each other into a new table, use `bind_cols`.

```{r, eval=FALSE}
## bind_rows
A = data.frame(x=1:5, y = rnorm(5))
B = data.frame(x=11:15, y = rnorm(5))
C = bind_rows(A,B)

## kolommen die niet in een van de data frames zitten worden aangevuld
E = data.frame(x=21:25, y = rnorm(5), z = rnorm(5))

bind_rows(A,E)
```

two data sets next to each other

```{r, eval=FALSE}
A = data.frame(x=1:5, y = rnorm(5))
B = data.frame(q=11:15, q = rnorm(5))
bind_cols(A,B)

## als een van de data frames meer rijen heeft, dan wordt er NIET aangevuld
A = data.frame(x=1:5, y = rnorm(5))
B = data.frame(q=11:17, q = rnorm(7))
bind_cols(A,B)
```

<br>

## Tidy data and wide data

---

Tidy data is data in the following form:

* Each variable is a column.
* Each observation is a row.
* Each value is a cell.

Suppose we have the following data:

```{r, eval=FALSE}
library(tidyr)
stocks = data.frame(
  time = as.Date('2009-01-01') + 0:9,
  X = rnorm(10, 0, 1),
  Y = rnorm(10, 0, 2),
  Z = rnorm(10, 0, 4)
)
stocks
```

Sometimes it is useful to have data values in one column and a separate column that represents the corresponding variable.

```{r, eval=FALSE}
stocksm = stocks %>% gather(stock, price, -time)
stocksm
```

And with the function `spread` you can reverse the process.

```{r, eval=FALSE}
stock2 = stocksm %>% spread(stock, price)
stock2
 
## als er niet even veel observaties zijn?

test = data.frame(
  T = c(1,2,3,1,2), 
  V = c("A","A","A","B","B"),
  price = c(4,5,6,7,8)
)

test2 = test %>% spread(V,price)
test2
```

A useful function in tidyr is `separate`, you can use this to separate data that is in one column. By default, non alpha-numeric characters are not used as separators.

```{r, eval=FALSE}
df = tibble(x = c("A.B", "C.P", "P.Q"))
df %>% separate(x, c("Kol1", "Kol2"))

## Er kunnen tw weinig of teveel kolommen zijn.
df = tibble(x = c("A.B", "C.P", "P.Q", "pp", "P.2.4"))
df %>% separate(x, c("Kol1", "Kol2"))


df = tibble(x = c("A.B", "C.P", "P.Q", "pp", "P.2.4"))
df %>% separate(x, c("Kol1", "Kol2", "Kol3"))
```

<br>


## Manipulating character data with `stringr`

---

Character data (strings) in R can be manipulated with the `stringr` package. Before we go further, it is useful to know what regular expressions are.

### Regular expressions

Regular expressions are a sort of 'mini' language to specify character patterns, so that you can search on those patterns in texts. First create some dummy character data.


```{r, eval=FALSE}
test = c("Mijn nummer is 06-12345678", "dit is .. een 1628EP postcode test", "foutje?:  0234XD", "dit is er nog een 1628 EP", "en nog een foute 126EP", "nog een 1234    XX", "1234eZ en nog 4567PK", "12345 Aabcde", "&yfy.")
test
```

A few examples of regular expressions.

```{r, eval=FALSE}
library(stringr)

## een digit, en precies 1 digit
patroon = "\\d"
str_extract(test, patroon)

## 1 of meerdere digits
patroon = "\\d+"
str_extract(test, patroon)

## precies twee letters
patroon ="[[:alpha:]]{2}"
str_extract(test, patroon)

## Een postcode
patroon = "\\d{4}\\s?[[:alpha:]]{2}"
str_extract(test, patroon)

## Maar een postcode begint niet met een 0
patroon = "[1-9]\\d{3}\\s?[[:alpha:]]{2}"
str_extract(test, patroon)

## special punctuation characters !"#$%&’()*+,-./:;<=>?@[]^_`{|}~
patroon = "[[:punct:]]"
str_extract(test, patroon)
```

A nice cheat sheet on regular expressions can be found here: [regex cheatsheet](https://www.rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf)

## Dates and times in R

---
To work with dates (and times) in R, the packages `anytime` and` lubridate` are very useful. Let's assume that we have characters with dates and want to use them in calculations. Then we can use the `anydate` function from the anytime package or one of the `ymd` functions.

```{r, eval=FALSE}
library(lubridate)
library(anytime)

y = c("1973-09-12", "1980-05-23", "1981-12-09")

testdata = tibble(DoB = y)

testdata = testdata %>%
  mutate(
    GeboorteDatum = anydate(DoB),
    GeboorteDatum2 = ymd(DoB)
  )
```

The function `anydate` parses various character notations to a date value, this usually goes as OK :-)

```{r, eval=FALSE}
y = c("1973/09/12", "05/23/1980", "23/05/1980","1981-12-09")

testdata = tibble(DoB = y)

testdata = testdata %>%
  mutate(
    GeboorteDatum = anydate(DoB)
  )
```

Now that we have a date as a date column in a data frame or tibble, we use it in calculations.

```{r, eval=FALSE}
testdata = testdata %>%
  mutate(
    leeftijd = today() - GeboorteDatum,
    leeftijd2 = as.numeric(today() - GeboorteDatum)/365,
    dag = wday(GeboorteDatum, label=TRUE)
  )
```

Time can also be represented in R

```{r, eval=FALSE}
tmp = paste("2018-01-23", c("12:01:33", "12:01:38", "12:01:58"))
Waarde = c(2.4, 5.6, 7.8)

MeetData = tibble(tmp = tmp, Waarde = Waarde)

MeetData = MeetData %>% 
  mutate(
    Meettijdstip = ymd_hms(tmp)
  )
```


# Data visualisation

---

## ggplot

The grammar or graphics, implemented in the package `ggplot2`, has become a standard in creating (basic) plots in R. A plot is created by laying layers on top of each other, each layer can be described with so-called * aesthetics * (styles). Each layer can be stored in a variable and these can be 'added' together to form a final plot.

Below is a first example of a ggplot on the `mtcars` data set.

```{r, eval=FALSE}
library(ggplot2)
library(dplyr)

## een laag p
p = ggplot(mtcars, aes(x=hp, y = mpg))

## wat is p
class(p)
typeof(p)

## voeg een laag punten toe
p = p + geom_point()
```

Show the plot by 'printing' it.

```{r, eval=FALSE}
p

q = geom_point( aes(x = hp, y = cyl), col=2)
r = p + q
r

## Een titel is ook een laag
p = p + 
  ggtitle("AUTO PLOTS \n EEN VOORBEELDJE") 
p
```

### Some more geom_... functions

There are several geom _ functions, we will show a few in the code chunks below.

Histograms are a useful way to quickly get an impression of the distribution of the data.


```{r, eval=FALSE}
#### histogrammen
p = ggplot(data = mpg, aes(displ)) 
  
p + geom_histogram()

## er zijn diverse opties die je mee kunt geven
p + geom_histogram(
  bins = 10,
  col="red",
  fill="green", 
  alpha = .82
) 
```

Box plots can also be used to get an impression of the distribution of the data. They contain visually less details than histograms, but you can more easily put multiple box plots next to each other. We use the `mpg` data set and look at the distribution of highway miles per gallon (hwy) for different types of cars.

```{r, eval=FALSE}
p = ggplot(mpg, aes(class, hwy)) + geom_boxplot()
p
```

You can also create grouped box plots and change the order of the box plots, for example on decreasing median.

```{r, eval=FALSE}
p = ggplot(
  mpg,
  aes(
    reorder(
      class,
      hwy,
      median
    ),
  hwy, 
  fill = factor(year)))

p + geom_boxplot()
```

### lines and smoothing lines

Line charts are useful for visualizing time series.

```{r, eval=FALSE}
df = data.frame(x=1:100, y=rnorm(100))

p = ggplot(
  df, 
  aes(x=x,y=y)
  )

p + geom_line()
p + geom_line(color="blue", size = 2)
```

When the x values are dates ggplot will take care of it!

```{r, eval=FALSE}
df = data.frame(
  x = anytime::anydate("2017-01-01") + 1:100,
  y = rnorm(100)
)

p = ggplot(
  df, 
  aes(x=x,y=y)
  )

p + geom_line()
```

Smoothing lines can be helpful when you want to see if there is a trend in a large scatter plot.

```{r, eval=FALSE}
restaurants = readr::read_csv("Restaurants.csv")

ggplot(data = restaurants, aes(aantalreviews, prijs)) + geom_point()

library(dplyr)
restaurants %>% 
  filter(prijs < 100, aantalreviews < 100) %>%
  ggplot(aes(aantalreviews, prijs)) +
  geom_point() +
  geom_smooth()
```

### bar plots

Bar plots can be useful to visualize counts per category. Let's for example look at top 10 kitchen types in the 'restaurant' data. I scraped this data from the Iens site a while ago, there are around 20,000 restaurants with a number of characteristics.

```{r, eval=FALSE, fig.width=10, fig.height=8}
restaurants = readr::read_csv("Restaurants.csv")

restaurants %>%
  group_by(
    keuken
  ) %>%
  summarise(
    n=n()
  ) %>%
  arrange(
    desc(n)
  ) %>% 
  filter(
    !is.na(keuken)
  ) %>%
  slice(1:10) %>%
  ggplot(aes(x = keuken)) + 
    geom_bar(aes(weight = n))
```

You can sort on the number of restaurants.

```{r, eval=FALSE, fig.width=12}
restaurants %>%
  group_by(
    keuken
  ) %>%
  summarise(
    n=n()
  ) %>%
  filter(
    !is.na(keuken)
  ) %>%
  arrange(
    desc(n)
  ) %>% 
  slice(1:10) %>%
  mutate(
    keuken = forcats::fct_reorder(keuken, n)
  ) %>%
  ggplot(aes(x=keuken)) + 
    geom_bar(aes(weight=n))

```

You can create stacked or grouped bar charts to visualize more dimensions.

```{r, eval=FALSE}
test = restaurants %>% 
  filter(
    plaats %in% c("Rotterdam", "Utrecht", "Amsterdam"),
    keuken %in% c("Internationaal", "Hollands", "Frans", "Italiaans")
  ) %>%
  group_by(
    keuken, plaats
  ) %>%
  summarise(n=n()) %>%
  filter(
    !is.na(keuken)
    )  %>% 
  arrange(
    desc(n)
  ) %>% 
  slice(1:10) 
   
##  in de aes kun je fill opgeven en met position kan je stacked of grouped opgeven 
test %>%
  ggplot(aes(x=keuken, y = n, fill = plaats)) + 
  geom_bar(stat="identity")

test %>%
  ggplot(aes(x=keuken, y = n, fill=plaats)) + 
  geom_bar(stat="identity", position = "dodge") 
```

Sometimes you want horizontal bar charts, to do plot that use a coordinate flip.

```{r, eval=FALSE}
test %>%
  ggplot(aes(x=keuken, y = n, fill=plaats)) + 
  geom_bar(stat="identity", position = "dodge") +
  coord_flip()
```

### geom_bin2d

Heat maps or 2D bin plots can be useful way to visualize data sets with many points. 

```{r, eval=FALSE}
df = data.frame(x=rnorm(100000), y=rnorm(100000))

ggplot(df, aes(x=x,y=y)) + geom_point()

ggplot(df, aes(x=x,y=y)) + geom_point( alpha=0.01 )

ggplot(df, aes(x=x,y=y)) + geom_bin2d()
```

### facets in ggplot

With `facets` you can make a matrix of plots. A simple example is if you want to create a histogram for men and women separately and put them next to each other or on top of each other in one graph. There are two functions in ggplot2 that support this, `facet_grid` and` facet_wrap`

```{r, eval=FALSE}
## ik zie niks....
restaurants %>%
  ggplot(
    aes(x=aantalreviews)
  ) +
  geom_histogram() + 
facet_wrap(~keuken)

top10 = restaurants %>%
  group_by(keuken) %>%
  summarise(n=n()) %>%
  arrange(desc(n)) %>% 
  filter(!is.na(keuken)) %>%
  slice(1:10)

restaurants %>%
  inner_join(top10) %>%
  ggplot(
    aes(x=aantalreviews)
  ) + 
  geom_histogram(col="black") + facet_wrap(~keuken, ncol = 5)
```


```{r, eval = FALSE}
restaurants %>% filter(prijs < 100) %>%
  inner_join(top10) %>%
  ggplot(
    aes(x=aantalreviews, y = prijs)
  ) + 
  geom_point() + facet_wrap(~keuken, ncol = 5)
```

There is a nice 'cheat sheet' for ggplot2, it contains a concise overview of the various possibilities and geom functions. The sheet can be found on [ggplot2 cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf)


## plotly

In addition to the statistical graphs we have made with ggplot2, you can also create interactive graphs in R. We give a number of examples in the following code chunks.

Plotly is a very nice library for creating interactive visualizations. For more info see [plotly] (https://plot.ly/r/). We will show you a few examples below.

### scatters

```{r, eval=FALSE}
library(plotly)
mtcars = mtcars
mtcars$naampjes = row.names(mtcars)

plot_ly(data = mtcars, x=~mpg, y = ~wt)
plot_ly(data = mtcars, x=~mpg, y = ~wt, color = ~cyl)
plot_ly(data = mtcars, x=~mpg, y = ~wt, text = ~naampjes)
```

### barcharts

We use the restaurants data set again for some plotly bar charts.

```{r,eval=FALSE}
Restaurants = readr::read_csv("Restaurants.csv")
keuken = Restaurants %>% dplyr::group_by(keuken) %>% dplyr::summarise(n=n())

p = plot_ly(data = keuken,
  x = ~keuken,
  y = ~n,
  type = "bar"
)

p
```

The plot above sorts the bars based on the kitchen types alphabetically, to sort it on descending number of restaurants we need to reorder the factor.

```{r, eval=FALSE}
keuken = keuken %>%
  mutate(
  keuken = forcats::fct_reorder(keuken,n, .desc=TRUE)
)
p = plot_ly(data = keuken,
  x = ~keuken,
  y = ~n,
  type = "bar"
)

p
```

### boxplots

```{r, eval=FALSE}
p = plot_ly(data = Restaurants, y = ~aantalreviews, color = ~keuken,type = "box")
p
```

### 3D plots

If you have 3D data you can plot it in a 3D scatter plot 

```{r, eval=FALSE}
p = plot_ly(data = mtcars, x=~mpg, y=~cyl, z = ~disp) 
p
```

A matrix with values can be plotted as a 3D surface plot

```{r, eval=FALSE}
volcano
plot_ly(z = ~volcano) %>% add_surface()
```

## leaflet

Leaflets are interactive maps based on open street maps.

```{r, eval=FALSE}
library(leaflet)

m = leaflet() %>%
  addTiles() %>%  # Add default OpenStreetMap map tiles
  addMarkers(lng=174.768, lat=-36.852, popup = "The birthplace of R")
m  

# kan geblokt worden door fire walls.
```

Plot the Restaurants of Zwolle on a leaflet. 

```{r, eval=FALSE}
Restaurants = readr::read_csv("Restaurants.csv")
Zwolle = Restaurants %>% filter(plaats == "Zwolle", LONGs < 7)

## tooltip teksten kunnen geplaatst worden
ptekst = paste(
  Zwolle$restNamen,
  '<BR> aantal reviews: ',
  Zwolle$aantalreviews)

m2 = leaflet(data = Zwolle)
m2 = m2 %>%
  addTiles() %>%  # Add default OpenStreetMap map tiles
  addMarkers(lng = ~LONGs, lat = ~LATs, popup = ptekst)
m2  
```

You can color the circles based on data: use `addCirclemarkers`

```{r, eval=FALSE}
reds = colorNumeric("Reds", domain = NULL)

Zwolle = Zwolle %>% filter(!is.na(aantalreviews), aantalreviews < 80)
ptekst = paste(Zwolle$restNamen, '<BR> aantal reviews: ', Zwolle$aantalreviews)

m2 = leaflet(data = Zwolle)
m2 = m2 %>%
  addTiles() %>%
  addCircleMarkers(
    lng = ~LONGs,
    lat = ~LATs, 
    fillColor = ~reds(aantalreviews), 
    fillOpacity = 1, popup = ptekst
  )
m2
```

## visnetwork

The `visnetwork` package can be used to create interactive graph (network) visualizations. You need two data frames, one with the nodes (also called vertices) and one with the edges (links). Let's start with a simple example.

```{r, eval=FALSE}
library(visNetwork)

nodes = data.frame(
  id = c(1,2,3,4)
)
edges = data.frame(
  from = c(1,3,4), 
  to  = c(2,2,2)
)

visNetwork(nodes, edges)
```

To alter the appearance of the graph several options can be provided trough the nodes and edges data frames.

```{r, eval=FALSE}
nodes = data.frame(
  id = 1:10,
  label = paste("Node", 1:10),                                   # labels
  group = c("GrA", "GrB"),                                       # groups
  value = 1:10,                                                  # size
  shape = c("square", "triangle", "box", "circle", "dot", "star", "ellipse", "database", "text", "diamond"),    # shape
  title = paste0("<p><b>", 1:10,"</b><br>Node !</p>"),           # tooltip
  color = c("darkred", "grey", "orange", "darkblue", "purple"),  # color
  shadow = c(FALSE, TRUE, FALSE, TRUE, TRUE))                    # shadow

edges = data.frame(from = sample(1:10,8), to = sample(1:10, 8),
  label = paste("Edge", 1:8),                                    # labels
  length = c(100,500),                                           # length
  arrows = c("to", "from", "middle", "middle;to"),               # arrows
  dashes = c(TRUE, FALSE),                                       # dashes
  title = paste("Edge", 1:8),                                    # tooltip
  smooth = c(FALSE, TRUE),                                       # smooth
  shadow = c(FALSE, TRUE, FALSE, TRUE))                          # shadow

visNetwork(nodes, edges)
```

Other options can be given via the `visnetwork` function. For example, highlight nearest:

```{r, eval=FALSE}
nodes = data.frame(
  id = 1:15,
  label = paste("Label", 1:15),
  group = sample(LETTERS[1:3], 15, replace = TRUE)
)

edges = data.frame(
  from = trunc(runif(15)*(15-1))+1,
  to = trunc(runif(15)*(15-1))+1
)

visNetwork(nodes, edges) %>% 
  visOptions(
    highlightNearest = TRUE,
    nodesIdSelection = TRUE
  )
```

Another network example: restaurant visitors in the beautiful city of Hoorn. When scraping the Iens website, you can also see that a reviewer has first reviewed a certain restaurant and then another. This is network information.

Focus now only on the beautiful city of Hoorn.

```{r, eval=FALSE}
Hoornnodes = readRDS("HoornNodes.RDs")
HoornEdges = readRDS("HoornEdges.RDs")

visNetwork(Hoornnodes, HoornEdges) %>% 
  visLegend() %>%
  visOptions(
    highlightNearest = TRUE, 
    nodesIdSelection = TRUE
  ) %>%
  visInteraction(
    navigationButtons = TRUE
  ) %>%
  visPhysics( maxVelocity = 25)
```

## zoomable cirlcepack plots

Circle packings are a nice way to visualize hierarchical data. For example click data or web path logs. First install the `circlepackeR` package from Git Hub.

```{r, eval = FALSE}
devtools::install_github("jeromefroe/circlepackeR")
```

Create some dummy data. The following code creates a hierarchical list.

```{r, eval= FALSE}
library(circlepackeR)

hierarchical_list = list(
  name = "World",
  children = list(
    list(name = "North America",
      children = list(
      list(
        name = "United States", size = 308865000),
        list(name = "Mexico", size = 107550697),
        list(name = "Canada", size = 34033000)
      )
    ),
    list(name = "South America", 
      children = list(
        list(name = "Brazil", size = 192612000),
        list(name = "Colombia", size = 45349000),
        list(name = "Argentina", size = 40134425)
      )
    ),
    list(name = "Europe",  
      children = list(
        list(name = "Germany", size = 81757600),
        list(name = "France", size = 65447374),
        list(name = "United Kingdom", size = 62041708)
      )
    ),
    list(name = "Africa",  
      children = list(
        list(name = "Nigeria", size = 154729000),
        list(name = "Ethiopia", size = 79221000),
        list(name = "Egypt", size = 77979000)
      )
    ),
    list(name = "Asia",  
      children = list(
        list(name = "China", size = 1336335000),
        list(name = "India", size = 1178225000),
        list(name = "Indonesia", size = 231369500)
      )
    )
  )
)
```

This list can now be plotted. 

```{r, eval=FALSE}
circlepackeR(hierarchical_list)
```

The above code manually creates a hierarchical list, obviously that is not not convenient way to plot more data. Fortunately there are some helper functions to create hierarchical data from data in data frames. Let's take the following data example from the treemap package.

```{r, eval = FALSE}
library(data.tree)
library(treemap)

# Gross national income data
data(GNI2014)
head(GNI2014)

# create one column with a path string
GNI2014 = GNI2014 %>% 
  mutate(
    webpath = paste("world", continent, country, sep = "/")
  )

# transform this data to a hierarchical tree that is suitable for circlepackR
# 
population = as.Node(GNI2014, pathName = "webpath")
circlepackeR(population,  size = "population")
circlepackeR(population,  size = "GNI")
```


# Machine learning

---

In R you can create different machine learning models, in this script I will demo supervised machine learning:

* regression, with lm
* classification, with glm, rpart and h2o

In supervised learning you are predicting an observed 'Target', observed 'behavior' from data. When this target is binary we have a classification problem. For example we observed whether or not customers responded to a mailing, whether or not a customer had a car accident. When this target is numeric we have a regression problem. 


I'll also show market basket analysis with the package `arules`. A technique to o analyse transaction data. For example physical purchases in supermarket or web clicks on a site.


## Lineare regression 

We start with simple linear regression, used for predictive models where the Target variable is continuous (numeric). We take as an example, house price data that I scraped from www.jaap.nl. We want to predict the price of a house based on a number of input variables / characteristics.

```{r, eval = FALSE}
jaap = readRDS("Jaap.RDs")

library(ggplot2)
ggplot(jaap, aes(prijs, kamers)) + geom_point()
ggplot(jaap, aes(prijs, Oppervlakte)) + geom_point()

# some obvious outliers
jaap = jaap %>% filter( prijs < 1e7 )
```

```{r, eval = FALSE}
modelout  = lm( prijs ~ kamers               , data = jaap)
modelout2 = lm( prijs ~ kamers + Oppervlakte , data = jaap) 

modelout
modelout2
```

Modeling functions in R return list objects with many 'things' in them. The `lm` function returns an object from the lm class.

```{r, eval = FALSE}
class(modelout)
names(modelout)
modelout$coefficients

summary(modelout)
plot(modelout)
```

You get something nicer diagnostic plots from `lm` objects with the` ggfortify` library, which knows how to interpret lm objects for ggplot. Then with the function 'autoplot' from ggplot you can make nicer diagnostic plots from regression results.

```{r, eval = FALSE}
library(ggfortify)
library(ggplot2)

ggplot2::autoplot(modelout)
```


```{r, eval=FALSE}
library(dplyr)
jaap = jaap %>% filter( prijs < 2000000 )
modelout  = lm( prijs ~ kamers               , data = jaap)
modelout2 = lm( prijs ~ kamers + Oppervlakte , data = jaap) 
```

### formula objects

You can specify models in R with so-called formula objects. A few examples are given in the code below.

```{r, eval = FALSE}
jaap = jaap %>% mutate(PC1Positie = stringr::str_sub(PC,1,1))

f0 = prijs ~ Oppervlakte + kamers 
m0 = lm(f0, data = jaap)
summary(m0)

f1 = prijs ~ Oppervlakte + kamers + PC1Positie
m1 = lm(f1, data = jaap)
summary(m1)

## interactie termen
f2 = prijs ~ Oppervlakte + kamers + PC1Positie + Oppervlakte*PC1Positie
m2 = lm(f2, data = jaap)
summary(m2)

## interactie termen
f3 = prijs ~ Oppervlakte + kamers + PC1Positie + Oppervlakte*PC1Positie +  Oppervlakte*kamers
m3 = lm(f3, data = jaap)
summary(m3)

##  interactietermen
f4 = prijs ~ Oppervlakte*kamers*PC1Positie 
m4 = lm(f4, data = jaap)
summary(m4)
```

If you have created different model objects, you can use the `anova` function to compare them. This is done with the help of F statistics. The models must be increasingly more complex.

```{r, eval =FALSE}
anova(m0, m1, m2, m3, m4)
```

A few more examples of formula objects.

```{r, eval=FALSE}
##  termen weglaten
f5 = prijs ~ Oppervlakte*kamers*PC1Positie - Oppervlakte:kamers:PC1Positie
m5 = lm(f5, data = jaap)
summary(m5)

## een target en de rest van de variabelen als inputs
f6 = prijs ~ . -PC6 -PC
m6 = lm(f6, data = jaap)
summary(m6)
```

### Buckets / linear constant  and splines 

If an input variable is not linear with respect to the target, you can not model it linearly with buckets (linear constant parts) or with splines.

```{r, eval = FALSE}
library(ggplot2)
library(dplyr)
library(splines)

jaap %>% filter(prijs < 1000000, Oppervlakte < 1500) %>%ggplot(aes(x=Oppervlakte, y= prijs)) + geom_point()

mybreaks = seq(0,1000, by = 25)
jaap = jaap %>% mutate(OppervlakteBucket = cut(Oppervlakte, breaks = mybreaks))


m1 = lm(prijs ~ Oppervlakte, data = jaap)
m2 = lm(prijs ~ OppervlakteBucket, data = jaap)
m3 = lm(prijs ~ ns(Oppervlakte,6), data = jaap)

summary(m1)
summary(m2)
summary(m3)

```

###  Predictions

With the `predict` function we can now score any house for which you want to determine a price, i.e. predict the price of houses that were not our training data set.

```{r, eval=FALSE}
NieuweHuizen = data.frame(
  Oppervlakte = seq(20, 250, l = 100)
  ) %>%
  mutate(
   OppervlakteBucket = cut(Oppervlakte, breaks = mybreaks)
  )

# Bucket predicties
prijs2 = predict(m2, newdata = NieuweHuizen)
NieuweHuizen$prijs2 = prijs2

ggplot(NieuweHuizen, aes(x=Oppervlakte, y = prijs2)) + geom_line()

# Spline predicties
prijs3 = predict(m3, newdata = NieuweHuizen)
NieuweHuizen$prijs3 = prijs3


ggplot(NieuweHuizen, aes(x=Oppervlakte, y = prijs2)) + geom_point() + geom_point(aes(y=prijs3), col=2)

```

## Classification

We use insurance data from the library `insuranceData` to demonstrate classification models. This data set is based on anonymized one-year vehicle insurance policies taken out in 2004 or 2005. There are 67856 policies, of which 4624 (6.8%) had at least one claim. 

Variables:

* veh_value	 vehicle value, in $10,000s
* exposure   0-1  indication of how much the car has driven
* clm        occurrence of claim (0 = no, 1 = yes)
* numclaims  number of claims
* claimcst0  claim amount (0 if no claim)
* veh_body   vehicle body, for example hatchback, minivan etc.
* veh_age    age of vehicle: 1 (youngest), 2, 3, 4
* gender     gender of driver: M, F
* area       driver's area of residence: A, B, C, D, E, F
* agecat     driver's age category: 1 (youngest), 2, 3, 4, 5, 6

```{r, eval=FALSE}
### libraries needed
library(insuranceData)
library(yardstick)
library(rpart)
library(visNetwork)
library(h2o)
library(rsample)
library(dplyr)
library(pROC)
library(lime)

data("dataCar")
```

The target should be a factor variable when doing classification

```{r, eval = FALSE}
dataCar = dataCar %>%
  mutate(
    Target = as.factor( ifelse( clm < 1, "N", "Y"))
  )

table(dataCar$Target)
```

### split data set

```{r, eval=FALSE}
TT = rsample::initial_split(dataCar)
trainData = training(TT)
testData = testing(TT)
```

### Logistic regression

A logistic regression can be seen as a generalization of the linear regression model. It is a linear regression model in the *log odds*. When you plot a binary target against an input variable, it is often hard to see a relation. Use a smoothing plot.

```{r, eval=FALSE}
library(ggplot2)
ggplot(trainData, aes(x=exposure,y=clm)) + geom_point()
ggplot(trainData, aes(x=exposure,y=clm)) + geom_smooth()
```

We can use the function `glm` in R to fit / train logistic regression models in R.

```{r, eval = FALSE}
cars_glm = glm(
  Target ~ veh_value + exposure + gender + veh_body + area + veh_age,
  data = trainData,
  family = binomial
)

summary(cars_glm)
```

Interpretation of the coefficient $c$ for a variable $x$ is as follows. One unit increase in the variable $x$ means $\exp(c)$ more likely that you will claim. So positive coefficient values mean increase of claim probability when $x$ increases, and negative values mean a decrease of claim probability when $x$ increases.

### Decision tree

A decision tree is a recursive partitioning of the data. High over, it splits data into two parts based so that the mean target values in the two pieces differ the most. 

```{r, eval=FALSE}
cars_tree = rpart(Target ~ . -numclaims - claimcst0 - clm, data = trainData)

plot(cars_tree)
text(cars_tree)

cars_tree = rpart(
  Target ~ . -numclaims - claimcst0 - clm, 
  data = trainData,
  control = rpart.control(cp = 0.00010)
)

visTree(
  cars_tree, 
  height = "800px", 
  nodesPopSize = TRUE, 
  minNodeSize = 10, maxNodeSize = 30
)
```

### Random forest and Boosted trees

A single decision tree is a nice interpretable model, but often the predictive power is not good, the model might be too simple. The last say, 8 years, random forests and boosted trees, became very popular. They are so called ensemble methods, a collection of multiple trees. 

The package `h2o` has a good implementation of Random Forests and boosted trees. This library has its own execution engine, data need to be transferred from R to h2o.

```{r, eval = FALSE}
library(h2o)
h2o.init()

allvars = names(trainData)
exclude_vars = c("Target", "clm", "X_OBSTAT_", "numclaims", "claimcst0" )
inputvars = allvars[ ! allvars %in% exclude_vars]

trainh2o = as.h2o(trainData)
testh2o = as.h2o(testData)

tree_ensemble = h2o.gbm(
  x= inputvars,
  y= "Target",
  training_frame = trainh2o ,
  validation_frame = testh2o,
  ntrees = 150
)
```

## Variable importance

A nice output of tree based methods are the variable importance statistics. If an input variable is used often in splitting, then that variable is important. For our claims data set we can see which variable were important in building the tree and which variables were not important.

```{r, eval=FALSE}
cars_tree$variable.importance
h2o.varimp_plot(tree_ensemble)
```

## How good is the model?

We have used only a part of all claims to train the model. Now we use the other part, the test set to evaluate the model. We use the model to predict for each each person in the test set the probability that he/she will claim. We know the actual result so hopefully people with high predicted probability are the ones who actually claimed.

There is a generic `predict` function that you can use, it takes a model object and a data set for which you want to calculate predictions, and possibly other parameters.

```{r, eval = FALSE}
## logistic regression model

### example call
predict(cars_glm, newdata = testData, type = "response")

### put the predictions inside the testData data frame
testData = testData %>% mutate(
  glm_prediction = predict(cars_glm, newdata = testData, type = "response")
)
```

For a decision tree the output of predict is slightly different.

```{r, eval = FALSE}
## decision tree

### example call
predict(cars_tree, newdata = testData)

### put the predictions inside the testData data frame
testData = testData %>% mutate(
  tree_prediction = predict(cars_tree, newdata = testData)[,2]
)
```

The gbm model in h2o is slightly more tricky, the following statement predicts
on the data in h2o, if we want to use it in R we need to bring it to R 

```{r, eval=FALSE}
predict(tree_ensemble, testh2o)

## bring h2o predictions to R, and directly in the testData data frame
testData = testData %>% mutate(
  ensemble_prediction = predict(
    tree_ensemble, testh2o) %>% 
    as.data.frame() %>%
    .[,3]
)
```

### Lift percentages

If we do not use a model, we can calculate the overall claim percentage

```{r, eval=FALSE}
## if you know nothing :-)
testData %>%  summarise(target = mean(clm))
```

If we have a good model, we would be able to use the model scores to identify a (small) group of people who have a (much) higher claim percentage. Let's look at the highest 10% model scores.

```{r, eval=FALSE}
testData = testData %>% 
  mutate(
    percGLM = cut(
      glm_prediction, 
      breaks = quantile(
        glm_prediction, 
        probs = (0:10)/10
      )
    ),
    percENSEMBLE = cut(
      ensemble_prediction, 
      breaks = quantile(
        ensemble_prediction, 
        probs = (0:10)/10
      )
    )
  )

## first impression of the scores of glm and tree ensemble model
ggplot(testData, aes(ensemble_prediction)) +
  geom_histogram(color="black", bins = 50) +
  geom_histogram(aes(glm_prediction), alpha = 0.2, color = "green", bins = 50)

## if you have a score!!!
testData %>% group_by(percGLM) %>%  summarise(target = mean(clm))
testData %>% group_by(percENSEMBLE) %>%  summarise(target = mean(clm))
```

### Receiver Operating Characteristic (ROC) Curve

For our claims model we have a predict claim score/probability. Now, if we choose a threshold, say 0.50 and predict: a person will claims if his score is larger than 0.5 and will not claim if his score is smaller than 0.5, we can see on our test data set true positives and false positives. The ROC curve is then created by plotting the true positive rate (TPR, or also called sensitivity) against the false positive rate (FPR, also known as specificity) at various threshold values.

We can use the `pROC` package in R to create such curves

```{r, eval=FALSE}
rocGLMclaims = roc(clm  ~ glm_prediction,  data = testData )
rocTREEclaims = roc(clm  ~ tree_prediction,  data = testData )

plot(rocGLMclaims)
plot(rocTREEclaims, col=2, add=TRUE)
```

```{r, eval = FALSE}
testData %>% roc_auc(Target, prediction)
testData %>% roc_auc(Target, tree_prediction)
```

### Explain the model, please?

When training random forest or boosting models, it is often hard to explain the model.  I.e. why will the model predict for customer X a high claim probability and why does it predict for customer Z a low claim probability?


The package `lime` can shed some insights into a model decision algorithm. It does this by looking at the top predictor variables and plot their effect on the model prediction.

```{r, eval = FALSE}
## Given the training data and the model to explain, create ann explainer
explainer = lime(
  trainData,
  tree_ensemble
)

## now we can explain specific cases
# Let's take two cases with high exposure and low exposure
explain_cases = bind_rows( 
  trainData %>% filter(exposure > 0.6) %>% slice(1:2),
  trainData %>% filter(exposure < 0.1) %>% slice(1:2)
)

# explain the 6 cases in terms of the top 5 features
explanation = lime::explain(
  explain_cases,
  explainer, 
  n_labels = 2,
  n_features = 5
)

plot_features(explanation)
```

## Market basket analysis (MBA)

With market basket analysis (also called association rules mining) you can identify from transaction data which products are often bought together. This can be used for product recommendations. This kind of analysis originally started in the supermarket branch, but you can apply MBA to any transaction data. Web-traffic for example, which pages are often visited together. 

We use a fictional supermarket data set in the following analysis. From transaction data, in R the data must be converted to a single `transaction object`. You can do this with the package 'arules'.

```{r, eval = FALSE}
library(arules)

## De meest simpele transactionele data set
trxDF = readRDS("boodschappen.RDs")

## Transormeer naar een transaction object
Groceries = as(
  split(
    trxDF$item,
    trxDF$id
    ),
  "transactions"
)
Groceries

## Item information
itemFrequencyPlot(Groceries, topN = 35, cex.names = 0.75)

## Calculate the rules
rules = apriori(Groceries, parameter = list(supp = 0.001, conf = 0.8))
```

Now that you have calculated the rules you can filter the rules by items. So which rules contain certain products?

```{r, eval = FALSE}
rules.subset2 = subset(rules, lhs %in% c("cereals", "curd"))
rules.subset2
inspect(head(rules.subset2,n=15))
```

Or if someone has bought already certain items, what are the rules that correspond with those items, and which products can you then recommend?


```{r, eval = FALSE}
PersoonA = data.frame(
  id = rep(1,3),
  item2 = c("butter","curd","domestic eggs")
)

trxs_trans = as(
  split(
    PersoonA$item2,
    PersoonA$id
    ),
  "transactions"
)
inspect(trxs_trans)

rulesMatch = is.subset(rules@lhs,trxs_trans)

## er zijn meerdere regels, je zou degene met de hoogste lift kunnen kiezen
inspect(rules[rulesMatch[,1]])
inspect(rules[rulesMatch[,1]]@rhs)
```

Another way to visualize the rules is in a network graph, the set of rules is actually a network. A -> B, B -> C, D -> B for example.

```{r, eval=FALSE}
library(arulesViz)
plot(head(sort(rules, by = "lift"), n=50), method = "graph", control=list(cex=.8))
```

### interactive MBA graphs

You can visualize rules using interactive plotly plots or interactive visNetwork plots. First, an interactive scatter plot of the rules can be made. Each rule is plotted as a point, where the x axis represents the support and the y axis represent the confidence of the rule.

```{r, eval=FALSE}
rules = apriori(Groceries, parameter = list(supp = 0.001, conf = 0.8) )
rulesDF = rules %>% DATAFRAME()

library(plotly)
plotly_arules(rules, max = 2000)
plotly_arules(rules, method = "two-key plot")
```

Secondly, an interactive visNetwork can be created. We need to extract the nodes and edges from the rules object.

```{r, eval=FALSE}
library(visNetwork)

rules = apriori(
  Groceries, 
  parameter = list(
    supp = 0.0001, 
    conf = 0.1, 
    minlen = 2,
    maxlen=2
    )
  )

rulesDF = head(
  sort(rules, by = "lift"),
  n=250
  ) %>% 
  DATAFRAME() %>%
  mutate(
    from = as.character(LHS),
    to = as.character(RHS),
    value = lift
  )

nodes = data.frame(
  id = base::unique(c(rulesDF$from, rulesDF$to)),
  stringsAsFactors = FALSE
) %>% mutate(
  title = id
)

visNetwork(nodes, rulesDF) %>%
   visOptions(highlightNearest = TRUE,  nodesIdSelection = TRUE) %>%
   visEdges(smooth = TRUE) 
```

<br>

*THE END*
